{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use AutoTunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find instructions on how to use AutoTunes. For expository purposes, I am using a small set of songs which you can find in the $\\text{gameboy_MIDI.zip}$ but for higher quality (or longer length) music, I'd recommend using a larger collection. For the time being, I assume you've extracted the contents from $\\text{gameboyMIDI.zip}$ into a folder titled $\\text{gameboyMIDI}$. If you'd like to use your own set of MIDI files, simply replace the path with the appropriate name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import Notes\n",
    "from Muse import AutoTunes\n",
    "import torch\n",
    "\n",
    "USE_CUDA  = torch.cuda.is_available()\n",
    "processor = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "training_music_path = \"gameboyMIDI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a Notes object using this data. This will partition the data into two collections of notes, $\\text{cur_notes}$ and $\\text{next_notes}$, where for each index $i$, $\\text{next_notes}[i]$ is the set of notes following $\\text{cur_notes}[i]$. Additionally, it'll also divide the songs into small snippets with a fixed number of timesteps. By default, I set it to 32 timesteps through the $\\text{seq_len}$ parameter, but you may change it as you see fit. We'll also note that this saves a copy of the data as a tensor so that you can reload the data without having to preprocess it first. If you've already done this, then set $\\text{MIDI} = \\text{False}$ and change the path to the saved file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameboy_music = Notes(training_music_path, MIDI=True, seq_len=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the AutoTunes model from Muse. By default, it assumes that the songs have sequence lengths of 32, but you may customize this as well if you changed the number of timesteps when you loaded the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse = AutoTunes().to(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the train method to train our AutoTunes object with the selected dataset. For validation purposes, you should use a different dataset for generating songs than the training set, but for the purposes of this demonstration, we shall play more wild and loose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse.train(gameboy_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the $\\text{create_music}$ method to generate new music based off the seed partition from our dataset. By default, it'll store the music in the $\\text{generated_samples}$ folder, but you can change this by changing the $\\text{midi_folder}$ parameter in the $\\text{create_music}$ method. We need to use some songs as seeds for the music generation. Each Notes object comes with a list of seeds which were not used during training and hence can be used for music generation.\n",
    "\n",
    "There's also a threshold parameter $\\text{thresh}$ which controls (roughly) how many notes your new song will have, with a lower number entailing a larger number of notes per timestep. You may have to play with the value of the depending on the dataset and its size. For the $\\text{gameboyMIDI}$ folder, 0.26 seems to work out fine, but I recommend experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = gameboy_music.seeds\n",
    "muse.create_music(seeds, thresh=0.26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the model's output as MIDI files, which might be cumbersome to play. I recommend importing them to [Online Sequencer](https://onlinesequencer.net/import) and choosing an adequate instrument to use with the music. My personal favorites are \"Synth Pluck\",\"Concert Harp\" and \"Scifi\" but you should definitely explore and see what you like. Some of the snippets of music you form may not be to your liking. This is especially the case if the randomly chosen seed is very sparse or not that pleasant in the first place. Feel free to simply create more until you find one you like. The larger the dataset you use to train, the more stability you'll find in the model. \n",
    "\n",
    "For reference, using SNES songs for training and GameBoy songs as seeds for generating music, we produced the following clips:\n",
    "\n",
    "[Clip 1](https://www.youtube.com/watch?v=jBg0v-mOAN0)\n",
    "\n",
    "[Clip 2](https://www.youtube.com/watch?v=kKFUJWCmJzQ)\n",
    "\n",
    "[Clip 3](https://www.youtube.com/watch?v=Ilj7s7OvUa8)\n",
    "\n",
    "For comparison, I'm also attaching the seeds used for generation for each clip:\n",
    "\n",
    "[Seed for Clip 1](https://www.youtube.com/watch?v=hL-20_ZUwSw)\n",
    "\n",
    "[Seed for Clip 2](https://www.youtube.com/watch?v=upahaJC-zDg)\n",
    "\n",
    "[Seed for Clip 3](https://www.youtube.com/watch?v=GiJC6MxM2CU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
