{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use IndieMuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find instructions on how to use IndieMuse. For expository purposes, I am using a small set of songs which you can find in the $\\text{gameboy_MIDI.zip}$ but for higher quality (or longer length) music, I'd recommend using a larger collection. For the time being, I assume you've extracted the contents from $\\text{gameboy_MIDI.zip}$ into a folder titled $\\text{gameboy_MIDI}$. If you'd like to use your own set of MIDI files, simply replace the path with the appropriate name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import Notes\n",
    "from Muse import IndieMuse\n",
    "import torch\n",
    "\n",
    "USE_CUDA  = torch.cuda.is_available()\n",
    "processor = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "training_music_path = \"gameboy_MIDI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a Notes object using this data. This will partition the data into two collections of notes, $\\text{cur_notes}$ and $\\text{next_notes}$, where for each index $i$, $\\text{next_notes}[i]$ is the set of notes following $\\text{cur_notes}[i]$. Additionally, it'll also divide the songs into small snippets with a fixed number of timesteps. By default, I set it to 32 timesteps through the $\\text{seq_len}$ parameter, but you may change it as you see fit. We'll also note that this saves a copy of the data as a tensor in the $\\text{prepared_data}$ folder so that you can reload the data without having to preprocess it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameboy_music = Notes(training_music_path, MIDI=True, seq_len=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the IndieMuse model from Muse. By default, it assumes that the songs have sequence lengths of 32, but you may customize this as well if you changed the number of timesteps when you loaded the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse = IndieMuse().to(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the train method to train our IndieMuse object with the selected dataset. For validation purposes, you should use a different dataset for generating songs than the training set, but for the purposes of this demonstration, we shall play more wild and loose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse.train(gameboy_music,gameboy_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the $\\text{create_music}$ method to generate new music based off the seed partition from our dataset. By default, it'll store the music in the $\\text{generated_samples}$ folder, but you can change this by changing the $\\text{midi_folder}$ parameter in the $\\text{create_music}$ method. It'll also store the original seed for comparison, but you may set the $\\text{save_seed parameter}$ to $\\text{False}$ if you're not interested in it. You can also load your own songs to use as seeds. If so, make sure to set the $\\text{use_model_seeds}$ parameter to $\\text{False}$ and give the model a dataset with processed music of the same number of timesteps as the training set.\n",
    "\n",
    "There's also a threshold parameter $\\text{thresh}$ which controls (roughly) how many notes your new song will have, with a lower number entailing a larger number of notes per timestep. You may have to play with the value of the depending on the dataset and its size. For the $\\text{gameboy_MIDI}$ folder, 0.25 seems to work out fine, but I recommend experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muse.create_music(thresh=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the model's output as MIDI files, which might be cumbersome to play. I recommend importing them to [Online Sequencer](https://onlinesequencer.net/import) and choosing an adequate instrument to use with the music. My personal favorites are \"Synth Pluck\",\"Concert Harp\" and \"Scifi\" but you should definitely explore and see what you like. Some of the snippets of music you form may not be to your liking. Feel free to simply create more until you find one you like. The larger the dataset you use to train, the more stability you'll find in the model. \n",
    "\n",
    "For reference, using SNES songs for training and GameBoy songs as seeds for generating music, we produced the following clips:\n",
    "\n",
    "[Clip 1](https://www.youtube.com/watch?v=jBg0v-mOAN0)\n",
    "\n",
    "[Clip 2](https://www.youtube.com/watch?v=kKFUJWCmJzQ)\n",
    "\n",
    "[Clip 3](https://www.youtube.com/watch?v=Ilj7s7OvUa8)\n",
    "\n",
    "For comparison, I'm also attaching the seeds used for generation for each clip:\n",
    "\n",
    "[Seed for Clip 1](https://www.youtube.com/watch?v=hL-20_ZUwSw)\n",
    "\n",
    "[Seed for Clip 2](https://www.youtube.com/watch?v=upahaJC-zDg)\n",
    "\n",
    "[Seed for Clip 3](https://www.youtube.com/watch?v=GiJC6MxM2CU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
